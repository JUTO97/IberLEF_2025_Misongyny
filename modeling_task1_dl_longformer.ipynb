{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback, AutoConfig\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from huggingface_hub import create_repo, upload_folder, notebook_login\n",
    "from utils_dl import set_global_seed\n",
    "\n",
    "try: \n",
    "    from sklearn.model_selection import StratifiedGroupKFold\n",
    "    GROUP_SPLITTER = StratifiedGroupKFold(n_splits=8,\n",
    "                                          shuffle=True,\n",
    "                                          random_state=42)\n",
    "except ImportError as e:\n",
    "    print('ImportError:', e)\n",
    "    GROUP_SPLITTER = None  # fallback later\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SUBTASK_1_PATH = \"new_data\\subtask1\"\n",
    "\n",
    "set_global_seed(SEED)\n",
    "notebook_login() # Log into HF account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "language = 'spa'\n",
    "model_type = 'dl'\n",
    "stemming = False\n",
    "lemmatization = False\n",
    "remove_duplicates = False\n",
    "cased = True \n",
    "\n",
    "data_config = f\"lang_{language}_model_{model_type}_stem_{stemming}_lem_{lemmatization}_dup_{remove_duplicates}_cased_{cased}\"\n",
    "file_name = 'subtask1_all_aug'\n",
    "db_file_name = f\"{file_name}_{data_config}.csv\"\n",
    "file_path = os.path.join(SUBTASK_1_PATH, db_file_name)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    full_data = pd.read_csv(file_path, encoding='utf-8')\n",
    "    # print(\"File found:\")\n",
    "    # print(full_data.info())\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For augmented data: samples sharing the same 'id' belong to the same original instance.\n",
    "full_data[\"id\"] = full_data[\"id\"].astype(str)\n",
    "full_data = full_data[full_data['augmentation_type'] != 'synonym_replacement'] \n",
    "full_data = full_data[full_data['augmentation_type'] != 'aeda_2'] # drop aeda_2 augmentation we use aeda_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column  = \"lyrics_clean\"\n",
    "label_column = \"label\"\n",
    "group_column = \"id\"             # all augmented variants share this id\n",
    "aug_col      = \"is_augmented\"   # bool\n",
    "final_training = False \n",
    "\n",
    "# labels\n",
    "if full_data[label_column].dtype == object:\n",
    "    unique_labels = sorted(full_data[label_column].unique())\n",
    "    label2id = {lbl: idx for idx, lbl in enumerate(unique_labels)}\n",
    "else:\n",
    "    unique_labels = sorted(full_data[label_column].unique())\n",
    "    label2id = {int(lbl): int(lbl) for lbl in unique_labels}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "full_data[label_column] = full_data[label_column].map(label2id)\n",
    "    \n",
    "# Splits\n",
    "full_data = full_data.sample(frac = 1, random_state=SEED) \n",
    "splits_folder_path =  os.path.join(SUBTASK_1_PATH, \"splits\") \n",
    "\n",
    "\n",
    "if not final_training:\n",
    "\n",
    "    train_file_name = 'train_ids.csv'\n",
    "    test_file_name = 'test_ids.csv'\n",
    "    val_file_name = 'val_ids.csv'\n",
    "    \n",
    "    train_file_path = os.path.join(splits_folder_path, train_file_name)\n",
    "    test_file_path = os.path.join(splits_folder_path, test_file_name)\n",
    "    val_file_path = os.path.join(splits_folder_path, val_file_name)\n",
    "    \n",
    "    # Get train ids\n",
    "    if os.path.exists(train_file_path):\n",
    "        unique_ids_df = pd.read_csv(train_file_path, encoding='utf-8')\n",
    "        # Select rows in full_data whose 'id' is in unique_ids\n",
    "        train_df = full_data[full_data['id'].isin(unique_ids_df['id'])].reset_index(drop=True)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found at {test_file_path}\")\n",
    "    \n",
    "    if os.path.exists(test_file_path):\n",
    "        unique_ids_df = pd.read_csv(test_file_path, encoding='utf-8')\n",
    "        # Select rows in full_data whose 'id' is in unique_ids\n",
    "        test_df = full_data[full_data['id'].isin(unique_ids_df['id'])].reset_index(drop=True)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found at {test_file_path}\")\n",
    "        \n",
    "    if os.path.exists(val_file_path):\n",
    "        unique_ids_df = pd.read_csv(val_file_path, encoding='utf-8')\n",
    "        # Select rows in full_data whose 'id' is in unique_ids\n",
    "        val_df = full_data[full_data['id'].isin(unique_ids_df['id'])].reset_index(drop=True)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found at {val_file_path}\")\n",
    "    \n",
    "else:\n",
    "    train_file_name = 'train_competition_ids.csv'\n",
    "    val_file_name = 'val_competition_ids.csv'\n",
    "    \n",
    "    train_file_path = os.path.join(splits_folder_path, train_file_name)\n",
    "    val_file_path = os.path.join(splits_folder_path, val_file_name)\n",
    "    \n",
    "    # Get train ids\n",
    "    if os.path.exists(train_file_path):\n",
    "        unique_ids_df = pd.read_csv(train_file_path, encoding='utf-8')\n",
    "        # Select rows in full_data whose 'id' is in unique_ids\n",
    "        train_df = full_data[full_data['id'].isin(unique_ids_df['id'])].reset_index(drop=True)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found at {train_file_path}\")\n",
    "        \n",
    "    if os.path.exists(val_file_path):\n",
    "        unique_ids_df = pd.read_csv(val_file_path, encoding='utf-8')\n",
    "        # Select rows in full_data whose 'id' is in unique_ids\n",
    "        val_df = full_data[full_data['id'].isin(unique_ids_df['id'])].reset_index(drop=True)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File not found at {val_file_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove augmented data from val / test\n",
    "if not final_training:\n",
    "    # *Train / Val / Test**\n",
    "    val_df  = val_df[val_df[aug_col]  != True]\n",
    "    test_df = test_df[test_df[aug_col] != True]\n",
    "    # print(f\"train={len(train_df)},  val={len(val_df)},  test={len(test_df)}\")\n",
    "else:\n",
    "    val_df  = val_df[val_df[aug_col]  != True]\n",
    "    # print(f\"train={len(train_df)}, val={len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not final_training: \n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "    val_dataset  = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "    test_dataset  = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "    \n",
    "    ds = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'val': val_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n",
    "   \n",
    "    \n",
    "else: # **Train / Val**\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "    val_dataset  = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "    \n",
    "    ds = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'val': val_dataset\n",
    "    })\n",
    "    \n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"PlanTL-GOB-ES/longformer-base-4096-bne-es\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, use_fast=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[text_column],\n",
    "        padding=False,  # dynamic later\n",
    "        truncation=True    \n",
    ")\n",
    "\n",
    "tokenized_ds = ds.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "columns_to_keep = {\"input_ids\", \"attention_mask\", label_column}\n",
    "for split in tokenized_ds.keys():    \n",
    "    tokenized_ds[split] = tokenized_ds[split].remove_columns([col for col in tokenized_ds[split].column_names if col not in columns_to_keep])\n",
    "    tokenized_ds[split] = tokenized_ds[split].rename_column(label_column, \"labels\")\n",
    "    tokenized_ds[split].set_format(\"torch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer,\n",
    "                                        pad_to_multiple_of=8,   # faster on tensor‑cores\n",
    "                                        return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Learning (HPO - Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for imbalanced data\n",
    "# Weighted loss: keep your data distribution but penalize errors on minority classes more heavily\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(unique_labels)),\n",
    "    y=train_df[label_column].to_numpy()\n",
    ")\n",
    "weight_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "# print(\"Class weights:\", weight_tensor)\n",
    "\n",
    "# Balanced sampling: over‑ or under‑sample examples so that each batch is roughly class‑balanced\n",
    "# sampling probabilities\n",
    "sample_weights = class_weights[train_df[label_column].to_numpy()]\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                replacement=True)\n",
    "\n",
    "\n",
    "class BalancedTrainer(Trainer):\n",
    "    def __init__(self, *args, weight_tensor: torch.Tensor = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if weight_tensor is None:\n",
    "            raise ValueError(\"You must pass weight_tensor\")\n",
    "        self.weight_tensor = weight_tensor\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # pop labels & forward\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        weight = self.weight_tensor.to(model.device)\n",
    "        loss_fct = CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    # balanced batches \n",
    "    def get_train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.per_device_train_batch_size,\n",
    "            sampler=sampler,\n",
    "            collate_fn=self.data_collator,\n",
    "            drop_last=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(unique_labels)\n",
    "optuna_path = \"./hpo_{}\".format(MODEL_CHECKPOINT.replace(\"/\",\"_\"))\n",
    "if os.path.exists(optuna_path):\n",
    "    shutil.rmtree(optuna_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # HPO\n",
    "    lr     = trial.suggest_float(\"learning_rate\", 1e-6, 5e-5, log=True)\n",
    "    wd     = trial.suggest_float(\"weight_decay\", 0.0, 0.3)\n",
    "    bsz    = trial.suggest_categorical(\"batch_size\", [6])\n",
    "    drop_h = trial.suggest_float(\"hidden_dropout\", 0.1, 0.4)\n",
    "    drop_a = trial.suggest_float(\"attn_dropout\", 0.1, 0.4)\n",
    "    drop_c = trial.suggest_float(\"classifier_dropout\", 0.1, 0.4)\n",
    "\n",
    "    # model_init used by Trainer\n",
    "    def model_init():\n",
    "        cfg = AutoConfig.from_pretrained(\n",
    "          MODEL_CHECKPOINT,\n",
    "          num_labels=len(unique_labels),\n",
    "          label2id=label2id,\n",
    "          id2label=id2label,\n",
    "          hidden_dropout_prob=drop_h,\n",
    "          attention_probs_dropout_prob=drop_a,\n",
    "          classifier_dropout=drop_c,\n",
    "        )\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "          MODEL_CHECKPOINT, config=cfg\n",
    "        )\n",
    "\n",
    "    # Training args\n",
    "    args = TrainingArguments(\n",
    "      output_dir                 = os.path.join(optuna_path, f\"trial_{trial.number}\"),\n",
    "      eval_strategy              = \"steps\",\n",
    "      eval_steps                 = 100,\n",
    "      logging_strategy           = \"steps\",\n",
    "      logging_steps              = 100,\n",
    "      save_strategy              = \"steps\",\n",
    "      save_steps                 = 100,\n",
    "      save_total_limit           = 1,\n",
    "      load_best_model_at_end     = True,\n",
    "      metric_for_best_model      = \"eval_f1\",\n",
    "      gradient_accumulation_steps = max(1, 32 // bsz), \n",
    "      greater_is_better          = True,\n",
    "      learning_rate              = lr,\n",
    "      weight_decay               = wd,\n",
    "      per_device_train_batch_size= bsz,\n",
    "      per_device_eval_batch_size = bsz,\n",
    "      num_train_epochs           = 12,\n",
    "      fp16                       = True,\n",
    "      seed                       = SEED,\n",
    "      report_to                  = \"none\",\n",
    "    )\n",
    "\n",
    "    # Trainer with early stop\n",
    "    trainer = BalancedTrainer(\n",
    "      model_init     = model_init,\n",
    "      args           = args,\n",
    "      train_dataset  = tokenized_ds[\"train\"],\n",
    "      eval_dataset   = tokenized_ds[\"val\"],\n",
    "      tokenizer      = tokenizer,\n",
    "      data_collator  = data_collator,\n",
    "      compute_metrics= compute_metrics,\n",
    "      weight_tensor  = weight_tensor,        # precomputed outside\n",
    "      callbacks      = [\n",
    "        EarlyStoppingCallback(early_stopping_patience=4),\n",
    "      ],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "    return metrics[\"eval_f1\"]\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model in Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: ./hpo_PlanTL-GOB-ES_longformer-base-4096-bne-es/trial_5/checkpoint-800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_trial = study.best_trial.number\n",
    "trial_dir = os.path.join(optuna_path, f\"trial_{best_trial}\")\n",
    "\n",
    "state_fp = os.path.join(trial_dir, \"trainer_state.json\")\n",
    "\n",
    "if not os.path.isfile(state_fp):\n",
    "    pat  = re.compile(r\"checkpoint-(\\d+)$\")\n",
    "    ckpt_dirs = [d for d in os.listdir(trial_dir) if pat.match(d)]\n",
    "    if not ckpt_dirs:\n",
    "        raise FileNotFoundError(f\"No checkpoints found in {trial_dir}\")\n",
    "\n",
    "    newest = max(ckpt_dirs, key=lambda d: int(pat.match(d).group(1)))\n",
    "    state_fp = os.path.join(trial_dir, newest, \"trainer_state.json\")\n",
    "\n",
    "    if not os.path.isfile(state_fp):\n",
    "        raise FileNotFoundError(\"trainer_state.json not found even in checkpoint.\")\n",
    "\n",
    "with open(state_fp) as f:\n",
    "    j = json.load(f)\n",
    "    best_ckpt_path = j[\"best_model_checkpoint\"]\n",
    "    best_epoch = j[\"epoch\"]\n",
    "\n",
    "print(\"Best checkpoint:\", best_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f2d502540a42a1840c684134ed50a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scaler.pt:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ee05d8786b4676af45a55b9c9870a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f252992d375d4979b08d766b412a793b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.pt:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253dc2dff2124b1aa5860dd6d11689f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a24a1745e2e41fda649b5c525b2c054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/595M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6c4382a71440f2adb3c2794745f0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d730021e5af84ba1b744539a44be9470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/SeTo97/longformer-base-4096-bne-es_ft_70_2/commit/3aac173d8ee243687e60f2e0c77db22ee1285722', commit_message=\"Best F1=0.7937 (trial 5)\\nHyper‑parameters: {'learning_rate': 1.1990640966033497e-05, 'weight_decay': 0.02779141111933888, 'batch_size': 6, 'hidden_dropout': 0.14305022315729415, 'attn_dropout': 0.2149871315628947, 'classifier_dropout': 0.1312020858420528, 'epoch': 3.861405197305101}\", commit_description='', oid='3aac173d8ee243687e60f2e0c77db22ee1285722', pr_url=None, repo_url=RepoUrl('https://huggingface.co/SeTo97/longformer-base-4096-bne-es_ft_70_2', endpoint='https://huggingface.co', repo_type='model', repo_id='SeTo97/longformer-base-4096-bne-es_ft_70_2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model     = AutoModelForSequenceClassification.from_pretrained(best_ckpt_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(best_ckpt_path)\n",
    "best_params = study.best_trial.params \n",
    "best_params['epoch'] = best_epoch\n",
    "\n",
    "repo_id = f\"SeTo97/{MODEL_CHECKPOINT.split('/')[-1]}_ft_70_2\"\n",
    "create_repo(repo_id, private=True, repo_type=\"model\", exist_ok=True)\n",
    "\n",
    "upload_folder(\n",
    "    repo_id        = repo_id,\n",
    "    folder_path    = best_ckpt_path,        # model + tokenizer together\n",
    "    repo_type      = \"model\",\n",
    "    commit_message = (\n",
    "        f\"Best F1={study.best_trial.value:.4f} \"\n",
    "        f\"(trial {study.best_trial.number})\\n\"\n",
    "        f\"Hyper‑parameters: {best_params}\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Evaluation (held-out test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1037/124484822.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "eval_loss: 0.6236\n",
      "eval_model_preparation_time: 0.0020\n",
      "eval_accuracy: 0.8157\n",
      "eval_precision: 0.8038\n",
      "eval_recall: 0.7911\n",
      "eval_f1: 0.7964\n",
      "eval_runtime: 10.3347\n",
      "eval_samples_per_second: 43.0590\n",
      "eval_steps_per_second: 5.4190\n"
     ]
    }
   ],
   "source": [
    "model_repo = repo_id\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_repo)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "test_dataset = tokenized_ds[\"test\"]\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator  \n",
    ")\n",
    "\n",
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11722456,
     "datasetId": 7012606,
     "sourceId": 11301557,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
