{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, logging, gc, os, numpy as np, pandas as pd, random\n",
    "import optuna, torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score,classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from huggingface_hub import create_repo, upload_folder, login, notebook_login\n",
    "from utils_dl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS_PATH = 'new_data/splits'\n",
    "CONFIG_PATH = \"config\"\n",
    "SUBTASK1_PATH = \"new_data/subtask1\"\n",
    "CONFIG_JSON       = os.path.join(CONFIG_PATH, \"ensemble_config.json\" )   \n",
    "SUBTASK1_CSV  =     os.path.join(SUBTASK1_PATH, 'subtask1_train_rev002.csv') \n",
    "VAL_CSV           = os.path.join(SPLITS_PATH, \"test_ids.csv\")  # test contains the training (never seen before) data.\n",
    "MODE              = \"stack\"  # \"soft\" or \"stack\"\n",
    "SEARCH_WEIGHTS    = True     # only for soft mode\n",
    "WEIGHT_TRIALS     = 30\n",
    "STACK_FOLDS       = 5\n",
    "STACK_TRIALS      = 150 \n",
    "SEED              = 42 # 123 550 101\n",
    "VAL_OUT_NPY       = \"val_preds.npy\"\n",
    "TEST_OUT_NPY      = \"test_preds.npy\"\n",
    "\n",
    "TASK1_OUT_PATH = 'new_data/subtask1/submisions'\n",
    "TASK1_OUT_CSV  = \"track_1_predictions.csv\"\n",
    "\n",
    "MODEL_CHECKPOINT = 'Meta-Learner (Logistic Regression)' if MODE == \"stack\" else MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "notebook_login() # Log into HF account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = json.loads(pathlib.Path(CONFIG_JSON).read_text())\n",
    "\n",
    "bundles = [\n",
    "    ModelBundle(\n",
    "        name=m[\"name\"],\n",
    "        path=m[\"path\"],\n",
    "        device=DEVICE,\n",
    "        batch_size=m.get(\"batch_size\", 32),\n",
    "        pad_multiple_of=m.get(\"pad_multiple_of\", 8),\n",
    "        fixed_max_length=m.get(\"fixed_max_length\"),  \n",
    "        preprocessing_config=m.get(\"preprocessing_config\")\n",
    "    )\n",
    "    for m in cfg[\"models\"]\n",
    "]\n",
    "\n",
    "subtask1_df =  pd.read_csv(SUBTASK1_CSV, encoding='utf-8') \n",
    "\n",
    "unique_val_ids_df = pd.read_csv(VAL_CSV, encoding='utf-8') \n",
    "val_df  = subtask1_df[subtask1_df['id'].isin(unique_val_ids_df['id'])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "text_col, label_col, group_col = cfg[\"text_col\"], cfg[\"label_col\"], cfg[\"group_col\"]\n",
    "\n",
    "# labels\n",
    "unique_labels = sorted(val_df[label_col].unique())\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(unique_labels)}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "val_df[label_col] = val_df[label_col].map(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition data\n",
    "test_df  = pd.read_csv(os.path.join(SUBTASK1_PATH, 'track_1_public_test_rev002.csv'), encoding='utf-8')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cache per model preprocessed DataFrames, we do it once and reuse in CV and final prediction \n",
    "preprocessed_val   = {}\n",
    "preprocessed_test  = {}\n",
    "for b in bundles:\n",
    "    conf = b.preprocessing_config\n",
    "    for src_df, tgt_dict in [(val_df, preprocessed_val), (test_df, preprocessed_test)]: \n",
    "        df_copy = src_df.copy()\n",
    "        df_copy[\"lyrics_clean\"] = df_copy[\"lyrics\"].apply(\n",
    "            lambda x: text_preprocess(\n",
    "                x,\n",
    "                lang=conf[\"lang\"],\n",
    "                remove_duplicates=conf[\"remove_duplicates\"],\n",
    "                cased=conf[\"cased\"],\n",
    "            )\n",
    "        )\n",
    "        tgt_dict[b.name] = df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning - Ensemble (Soft Voting and Stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted soft-vote\n",
    "def soft_vote_predict(df, weights=None):\n",
    "    probs = []\n",
    "    is_val = df is val_df\n",
    "    source = preprocessed_val if is_val else preprocessed_test\n",
    "    label_col = label_col if is_val else None\n",
    "    for b in bundles:\n",
    "        lg, _ = b.predict_logits(source[b.name], text_col, label_col)\n",
    "        probs.append(torch.softmax(torch.tensor(lg), dim=1).numpy())\n",
    "    probs = np.stack(probs)      # Shape: (num_models, num_samples, num_classes)\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(bundles)) / len(bundles) # Equal weight (uniform average)\n",
    "    probs = probs * weights[:, None, None] # reshapes to  (num_models, 1, 1)\n",
    "    return probs.sum(axis=0).argmax(axis=1) # Shape becomes: (num_samples, num_classes). Then argmax returns the index of the class with highest probability for each smple\n",
    "\n",
    "def optimise_soft_weights():    \n",
    "    def objective(trial):\n",
    "        # sample raw, unnormalized weights\n",
    "        raw = np.array([\n",
    "            trial.suggest_float(f\"w{i}\", 0.0, 1.0)\n",
    "            for i in range(len(bundles))\n",
    "        ])\n",
    "        # normalize\n",
    "        weights = raw / raw.sum()\n",
    "\n",
    "        # soft-vote with normalized weights\n",
    "        preds = soft_vote_predict(val_df, weights)\n",
    "        return f1_score(val_df[label_col], preds, average=\"macro\")\n",
    "\n",
    "    st = optuna.create_study(direction=\"maximize\",\n",
    "                             sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "    st.optimize(objective, n_trials=WEIGHT_TRIALS, show_progress_bar=False)\n",
    "    best_w = np.array([st.best_params[f\"w{i}\"] for i in range(len(bundles))])\n",
    "    print(\"best soft weights:\", np.round(best_w, 4))\n",
    "    return best_w\n",
    "\n",
    "def stacked_predict(val_df):\n",
    "    # Meta-learner\n",
    "    y      = val_df[label_col].values\n",
    "    groups = val_df[group_col].values\n",
    "    sgkf   = StratifiedGroupKFold(n_splits=STACK_FOLDS,\n",
    "                                  shuffle=True, random_state=SEED)\n",
    "\n",
    "    # build OOF probability matrix \n",
    "    oof = np.zeros((len(val_df), 2 * len(bundles)), dtype=np.float32)\n",
    "    for _, va in sgkf.split(val_df, y, groups):\n",
    "        for m_ix, b in enumerate(bundles):\n",
    "            df_clean = preprocessed_val[b.name].iloc[va]\n",
    "            logits, _ = b.predict_logits(df_clean, text_col, label_col)\n",
    "            probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "            oof[va, 2*m_ix : 2*(m_ix+1)] = probs\n",
    "\n",
    "    # HPO\n",
    "    def objective(trial):\n",
    "        solver = trial.suggest_categorical(\"solver\",\n",
    "                                           [\"liblinear\", \"saga\", \"lbfgs\"])\n",
    "        if solver == \"liblinear\":\n",
    "            penalty = trial.suggest_categorical(\"pen_lib\", [\"l2\", \"l1\"])\n",
    "            l1_ratio = None\n",
    "        elif solver == \"saga\":\n",
    "            penalty = trial.suggest_categorical(\"pen_saga\",\n",
    "                                                [\"l2\", \"l1\", \"elasticnet\"])\n",
    "            l1_ratio = (trial.suggest_float(\"l1_ratio\", 0.1, 0.9)\n",
    "                        if penalty == \"elasticnet\" else None)\n",
    "        else:\n",
    "            penalty, l1_ratio = \"l2\", None\n",
    "\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 10.0, log=True)\n",
    "\n",
    "        if trial.suggest_categorical(\"cw_type\", [\"balanced\", \"custom\"]) == \"balanced\":\n",
    "            cw = \"balanced\"\n",
    "        else:\n",
    "            w0 = trial.suggest_float(\"w0\", 1.0, 6.0)\n",
    "            cw = {0: w0, 1: 1.0}\n",
    "\n",
    "        meta = LogisticRegression(\n",
    "            solver=solver,\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            l1_ratio=l1_ratio,\n",
    "            class_weight=cw,\n",
    "            max_iter=2000,\n",
    "            random_state=SEED,\n",
    "        )\n",
    "\n",
    "        preds = np.zeros_like(y)\n",
    "        for tr, va in sgkf.split(oof, y, groups):\n",
    "            meta.fit(oof[tr], y[tr])\n",
    "            preds[va] = meta.predict(oof[va])    \n",
    "        return f1_score(y, preds, average=\"macro\")\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "    study.optimize(objective, n_trials=STACK_TRIALS, show_progress_bar=False)\n",
    "    bp = study.best_params\n",
    "\n",
    "    # train final meta on full OOF \n",
    "    cw_final = (\"balanced\" if bp[\"cw_type\"] == \"balanced\"\n",
    "                else {0: bp[\"w0\"], 1: 1.0})\n",
    "    final_meta = LogisticRegression(\n",
    "        solver=bp[\"solver\"],\n",
    "        penalty=bp.get(\"pen_lib\", bp.get(\"pen_saga\", \"l2\")),\n",
    "        C=bp[\"C\"],\n",
    "        l1_ratio=bp.get(\"l1_ratio\"),\n",
    "        class_weight=cw_final,\n",
    "        max_iter=2000,\n",
    "        random_state=SEED,\n",
    "    ).fit(oof, y)\n",
    "\n",
    "    def _meta_predict(df_raw):\n",
    "        feats = []\n",
    "        \n",
    "        is_val = df_raw is val_df        \n",
    "        src = preprocessed_val if is_val else preprocessed_test\n",
    "        label_col = 'label' if is_val else None\n",
    "        \n",
    "        for b in bundles:\n",
    "            df_clean = (preprocessed_val if df_raw is val_df\n",
    "                        else preprocessed_test)[b.name]\n",
    "            logits, _ = b.predict_logits(df_clean, text_col, label_col)\n",
    "            feats.append(torch.softmax(torch.tensor(logits), dim=1).numpy())\n",
    "        feats = np.concatenate(feats, axis=1)\n",
    "        return final_meta.predict(feats)         \n",
    "\n",
    "    return _meta_predict, bp\n",
    "\n",
    "\n",
    "# Run ensemble\n",
    "if MODE == \"soft\":\n",
    "    w_best = optimise_soft_weights() if SEARCH_WEIGHTS else None \n",
    "    test_preds = soft_vote_predict(test_df, w_best) # Competition data\n",
    "\n",
    "elif MODE == \"stack\":\n",
    "    meta_predict, best_params_meta = stacked_predict(val_df)\n",
    "    test_preds = meta_predict(test_df) # Competition data\n",
    "else:\n",
    "    raise ValueError(\"MODE must be 'soft' or 'stack'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved track_1_predictions.csv with 527 rows.\n"
     ]
    }
   ],
   "source": [
    "pred_labels = [id2label[i] for i in test_preds]  \n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],       \n",
    "    \"label\": pred_labels\n",
    "})\n",
    "\n",
    "submission.to_csv(os.path.join(TASK1_OUT_PATH, MODE, TASK1_OUT_CSV) , index=False, encoding=\"utf-8\")\n",
    "print(f\"Saved {TASK1_OUT_CSV} with {len(submission)} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11722456,
     "datasetId": 7012606,
     "sourceId": 11301557,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
